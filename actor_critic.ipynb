{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPVZcDg3V2GEdg6Zha/iYvl",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Calcifer777/learn-rl/blob/main/actor_critic.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install gymnasium"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FjOCLcV1DnZU",
        "outputId": "36ebb4ee-fddf-447c-aff2-1914c0bfc0a4"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting gymnasium\n",
            "  Downloading gymnasium-0.28.1-py3-none-any.whl (925 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m925.5/925.5 kB\u001b[0m \u001b[31m13.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium) (1.22.4)\n",
            "Collecting jax-jumpy>=1.0.0 (from gymnasium)\n",
            "  Downloading jax_jumpy-1.0.0-py3-none-any.whl (20 kB)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium) (2.2.1)\n",
            "Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium) (4.5.0)\n",
            "Collecting farama-notifications>=0.0.1 (from gymnasium)\n",
            "  Downloading Farama_Notifications-0.0.4-py3-none-any.whl (2.5 kB)\n",
            "Installing collected packages: farama-notifications, jax-jumpy, gymnasium\n",
            "Successfully installed farama-notifications-0.0.4 gymnasium-0.28.1 jax-jumpy-1.0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "237Q04Y1DSSi"
      },
      "outputs": [],
      "source": [
        "from collections import namedtuple\n",
        "from typing import List\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.distributions import Categorical\n",
        "import gymnasium as gym"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "DISCOUNT = 0.99"
      ],
      "metadata": {
        "id": "5VUC68y2LoBH"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "SEED = 42\n",
        "torch.random.manual_seed(SEED)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1o0Y2GChHcZt",
        "outputId": "edc1ee7a-b5ad-496e-8fb2-79c4ae322a33"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7fae2417a570>"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "SavedAction = namedtuple(\"SavedAction\", [\"log_prob\", \"value\"])"
      ],
      "metadata": {
        "id": "Xjh55P0_Gdzy"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Policy(nn.Module):\n",
        "  def __init__(self, inputs_dim, hidden_dim, outputs_dim):\n",
        "    super(Policy, self).__init__()\n",
        "    self.l1 = nn.Linear(inputs_dim, out_features=hidden_dim)\n",
        "    self.l2 = nn.Linear(hidden_dim, out_features=hidden_dim)\n",
        "    \n",
        "    self.action_head = nn.Linear(hidden_dim, outputs_dim)\n",
        "    self.value_head = nn.Linear(hidden_dim, 1)\n",
        "    \n",
        "    self.saved_actions: List[SavedAction] = []\n",
        "    self.rewards = []\n",
        "\n",
        "  def forward(self, x):\n",
        "    h = self.l1(x)\n",
        "    h = F.relu(h)\n",
        "    h = self.l2(h)\n",
        "    action_probs = F.softmax(self.action_head(h), dim=-1)\n",
        "    values = self.value_head(h)\n",
        "    return action_probs, values"
      ],
      "metadata": {
        "id": "ByGpDJzlDkko"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "policy = Policy(inputs_dim=4, hidden_dim=64, outputs_dim=2)"
      ],
      "metadata": {
        "id": "DancXfkEFUeM"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample = torch.rand((1, 4))"
      ],
      "metadata": {
        "id": "r8WeQ4LJFYI7"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "policy(sample)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JgxaFOW1Fmns",
        "outputId": "92f1d1a5-3b08-4d46-feda-e142325cbad1"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[0.5603, 0.4397]], grad_fn=<SoftmaxBackward0>),\n",
              " tensor([[-0.0392]], grad_fn=<AddmmBackward0>))"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def select_action(policy, state):\n",
        "  state = torch.from_numpy(state).float()\n",
        "  probs, value = policy(state)\n",
        "\n",
        "  action_distr = Categorical(probs)\n",
        "  action = action_distr.sample()\n",
        "\n",
        "  policy.saved_actions.append(\n",
        "      SavedAction(action_distr.log_prob(action), value)\n",
        "  )\n",
        "\n",
        "  return action.item()"
      ],
      "metadata": {
        "id": "aaojeS0rFqJ1"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "env = gym.make(\"CartPole-v1\")\n",
        "env.reset(seed=SEED)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2cE2yn-IHWxP",
        "outputId": "1b077faf-3e61-4904-d6c1-33be2b32695f"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([ 0.0273956 , -0.00611216,  0.03585979,  0.0197368 ], dtype=float32),\n",
              " {})"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "state, _ = env.reset()"
      ],
      "metadata": {
        "id": "mTBZjufNHw2b"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "action = select_action(policy, state)"
      ],
      "metadata": {
        "id": "JA7kocAwHTdD"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "NUM_EPISODES = 1000\n",
        "T = 475"
      ],
      "metadata": {
        "id": "imp5OdfUH-Rs"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "env.step(action)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IgacnHGCJCqX",
        "outputId": "cdb0c5de-7866-4b81-95f4-4d425d186a1a"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([-0.03963102,  0.24230015,  0.0266861 , -0.25572422], dtype=float32),\n",
              " 1.0,\n",
              " False,\n",
              " False,\n",
              " {})"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def run_episode(env, policy: Policy, max_time_steps: int=T):\n",
        "  state, _ = env.reset()\n",
        "  ep_reward = 0\n",
        "\n",
        "  for t in range(max_time_steps):\n",
        "    action = select_action(policy, state)\n",
        "    state, reward, done, _, _ = env.step(action)\n",
        "    policy.rewards.append(reward)\n",
        "\n",
        "    if done:\n",
        "      break"
      ],
      "metadata": {
        "id": "EcrieoM1JpCj"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "l = [4,2,3,1]\n",
        "list(reversed(l))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z28NjlfzK0xM",
        "outputId": "8f51572d-4986-449b-c55c-3766e8d53692"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1, 3, 2, 4]"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def backprop(policy: Policy):\n",
        "  actions = policy.saved_actions\n",
        "  rewards = policy.rewards\n",
        "\n",
        "  losses_policy, losses_value = [], []\n",
        "\n",
        "  # For each step, compute its value\n",
        "  values = []\n",
        "  accumulated_return = 0\n",
        "  for reward in reversed(policy.rewards):\n",
        "    accumulated_return = reward + DISCOUNT*accumulated_return\n",
        "    values.append(accumulated_return)\n",
        "  values = reversed(values)\n",
        "  values = torch.tensor(values)\n",
        "  values = (values - values.mean()) / values.std()\n",
        "\n",
        "  # For each step, compute the loss\n",
        "  for (logit, value_hat), value in zip(actions, values):\n",
        "    advantage = value - value_hat.item()\n",
        "    losses_policy.append(-logit*advantage)\n",
        "    losses_value.append(F.smooth_l1_loss(value_hat, torch.tensor([value])))\n",
        "    \n"
      ],
      "metadata": {
        "id": "BPkDf59yKBKd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for ep_idx in range(2):\n",
        "\n",
        "  run_episode(env, policy)"
      ],
      "metadata": {
        "id": "vn53JxeEH813"
      },
      "execution_count": 50,
      "outputs": []
    }
  ]
}